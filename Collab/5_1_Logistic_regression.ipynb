{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.1-Logistic-regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ejabril/nltk-training/blob/master/5_1_Logistic_regression.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "CqQlMefK6HZ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KsW2NotEKuf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WsOXDOOT-7sw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = load_iris().data\n",
        "y = load_iris().target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cwt5dheAwV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gzthF76SA453",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0vxIzw1A-b5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yq95wRRxBBgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DEexAXiBQtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22ZwhVmLBSoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.name_scope('input'):\n",
        "  input_features = tf.placeholder(dtype=tf.float32, shape=[None, x.shape[1]],\n",
        "                                 name='input_features')\n",
        "  input_labels = tf.placeholder(dtype=tf.float32, shape=[None, y.shape[1]],\n",
        "                               name='input_labels')\n",
        "\n",
        "  with tf.name_scope('model'):\n",
        "    weights = tf.Variable(tf.random_normal(shape=[x.shape[1], y.shape[1]]),\n",
        "                          name='weights')\n",
        "    biases = tf.Variable(tf.random_normal(shape=[y.shape[1]]))\n",
        "    linear_model = tf.add(tf.matmul(input_features, weights), biases)\n",
        "    predictions = tf.nn.softmax(linear_model)\n",
        "    \n",
        "with tf.name_scope('training_ops'):\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "      logits=linear_model, labels=input_labels))\n",
        "  train_op = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\n",
        "  tf.summary.scalar(name='loss', tensor=loss)\n",
        "\n",
        "with tf.name_scope('metrics'):\n",
        "  correct_prediction = tf.cast(tf.equal(tf.argmax(predictions, 1),\n",
        "                                         tf.argmax(input_labels, 1)), tf.float32)\n",
        "  accuracy_op = tf.reduce_mean(correct_prediction)\n",
        "  tf.summary.scalar(name='accuracy', tensor=accuracy_op)\n",
        "\n",
        "summary = tf.summary.merge_all()\n",
        "writer = tf.summary.FileWriter(logdir='logs', graph=tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiEIf7KzEULg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGLYrT7BEaSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size,features,labels):\n",
        "  indices = np.arange(start=0,stop=features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices],labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-hkL8WhE6Lx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "cef5c926-de17-4b1d-909c-0e21a6e0dec2"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf logs/\n",
        "!rm ngrok*\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-17 04:51:13--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.73.140.127, 52.72.251.164, 52.72.80.190, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.73.140.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-08-17 04:51:13 (42.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6c4VZin4Fo1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lr7JXr7GHFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRn0sYBIHvoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ffc7347-410e-4987-c40a-4be81b565604"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://9ef7a169.ngrok.io\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VGk1tuBEL6zv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, features, labels):\n",
        "  indices = np.arange(start=0, stop=features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices], labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ES692H_eIUry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "37f77c6e-5006-40d1-8757-073382f2fc9e"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "  \n",
        "  # epochs = 10\n",
        "  for epoch in range(10):\n",
        "    for mini_batch in range(int(x_train.shape[0] / 16)):\n",
        "      batch_x, batch_y = next_batch(batch_size=16, features=x_train, labels=y_train)\n",
        "      \n",
        "      _, train_loss, train_accuracy, train_summary = sess.run([train_op, loss,\n",
        "                                                               accuracy_op,\n",
        "                                                              summary],\n",
        "                                              feed_dict={input_features: batch_x,\n",
        "                                                        input_labels: batch_y})\n",
        "      writer.add_summary(summary=train_summary, global_step=mini_batch)\n",
        "    print('Epoch {}, loss : {}, accuracy : {}'.format(epoch, train_loss,\n",
        "                                                      train_accuracy))  \n",
        "  \n",
        "  test_accuracy = sess.run(accuracy_op, feed_dict={input_features: x_test, input_labels: y_test})\n",
        "  print('Test accuracy : {}'.format(test_accuracy))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss : 1.2522807121276855, accuracy : 0.75\n",
            "Epoch 1, loss : 0.669420599937439, accuracy : 0.75\n",
            "Epoch 2, loss : 0.33136042952537537, accuracy : 0.875\n",
            "Epoch 3, loss : 0.28608882427215576, accuracy : 0.9375\n",
            "Epoch 4, loss : 0.32035303115844727, accuracy : 1.0\n",
            "Epoch 5, loss : 0.25335392355918884, accuracy : 1.0\n",
            "Epoch 6, loss : 0.35887032747268677, accuracy : 0.8125\n",
            "Epoch 7, loss : 0.30329492688179016, accuracy : 0.875\n",
            "Epoch 8, loss : 0.3070489764213562, accuracy : 1.0\n",
            "Epoch 9, loss : 0.31013989448547363, accuracy : 0.9375\n",
            "Test accuracy : 0.9333333373069763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DyAoB34eKenA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}